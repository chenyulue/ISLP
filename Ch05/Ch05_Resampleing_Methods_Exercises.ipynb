{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptual\n",
    "\n",
    "**Q1**. Prove that $\\alpha$ given by (5.6) does indeed minimize $Var(\\alpha X + (1 - \\alpha) Y$.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "Three properties that is useful for the deduction:\n",
    "* $Cov(a \\cdot X, b\\cdot Y) = ab \\cdot Cov(X, Y)$\n",
    "* $Var(X \\pm Y) = Var(X) + Var(Y) \\pm 2Cov(X, Y)$\n",
    "* $Var(a \\cdot X) = a^2 Var(X)$\n",
    "\n",
    "$$\\begin{align}Var(\\alpha X + (1-\\alpha)Y) &= Var(\\alpha X) + Var((1-\\alpha)Y) + 2Cov(\\alpha X, (1-\\alpha)Y) \\\\ &= \\alpha^2 Var(X) + (1-\\alpha)^2 Var(Y) + 2 \\alpha (1-\\alpha) Cov(X, Y) \\end{align}$$\n",
    "\n",
    "When $Var(\\alpha X + (1-\\alpha)Y)$ gets a minimum value, its derivative should be zero such that:\n",
    "\n",
    "$$\\begin{align} 2\\alpha Var(X) - 2（1 - \\alpha)Var(Y) + (2 - 4\\alpha)Cov(X, Y) &= 0 \\\\ \\Longrightarrow \\alpha Var(X) + \\alpha Var(Y) - Var(Y) + Cov(X, Y) - 2 \\alpha Cov(X, Y) &= 0 \\\\ \\Longrightarrow \\alpha = \\frac{Var(Y) - Cov(X, Y)}{Var(X) + Var(Y) - 2Cov(X, Y)} \\\\ \\Longrightarrow \\alpha = \\frac{\\sigma_Y^2 - \\sigma_{XY}}{\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}}\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**. We will now derive the probability that a given observation is part of a bootstrap sample. Suppose that we obtain a bootstrap sample from a set of *n* observations.\n",
    "\n",
    "(a) What is the probability that the first bootstrap observation is *not* the *j*th observation from the original sample?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "Let us denote this probability by $P_j$. As the probability of selecting a particular $x_j$ from the set $x_1,...,x_n$ is $1/n$, then the desired probability is\n",
    "\n",
    "$$P_j = 1 - \\frac1n$$\n",
    "\n",
    "(b) What is the probability that the second bootstrap observation is *not* the *j*th observation from the original sample?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "The probability is $1 - \\frac1n$ with the same reason as above.\n",
    "\n",
    "(c) Argue that the probability that the *j*th observation is *not* in the bootstrap sample is $(1 - 1/n)^n$.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "As bootstrapping the sample with replacement, we have that the probability that the *j*th observation is not in the bootstrap sample is the product of the probabilities that each bootstrap observation is not the *j*th observation from the original sample\n",
    "\n",
    "$$(1-1/n)\\cdot \\cdot \\cdot(1-1/n) = (1-1/n)^n$$\n",
    "\n",
    "as these probabilities are independant.\n",
    "\n",
    "(d) When $n=5$, what is the probability that the *j*th observation is in the bootstrap sample?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "According to the description in (c), the probability that *j*th observation is in the bootstrap sample is $1 - (1 - 1/5)^5 = 0.672$.\n",
    "\n",
    "(e) When $n=100$, what is the probability that the *j*th observation is in the bootstrap sample?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "The probability is $1 - (1 - 1/100)^{100} = 0.634$.\n",
    "\n",
    "(f) When $n=10,000$, what is the probability that the *j*th  observation is in the bootstrap sample?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "The probability is $1 - (1 - 1/10000)^{10000} = 0.632$.\n",
    "\n",
    "(g) Create a plot that displays, for each integer value of $n$ from 1 to 100,000, the probability that the *j*th observation is in the bootstrap sample.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n = np.arange(1,100001)\n",
    "p = 1 - (1 - 1/n)**n\n",
    "plt.scatter(n, p)\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, we can see that the probability drops quickly and reaches an asymptote at about $0.632$.\n",
    "\n",
    "(h) We will now investigate numerically the probability that a bootstrap sample of size $n=100$ contains the *j*th observation. Here $j=4$. We repeatedly create bootstrap samples, and each time we record whether or not the fourth observation is contained in the bootstrap sample. Comment on the results obtained.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s = pd.Series(range(1,101))\n",
    "store = [sum(s.sample(frac=1, replace=True)==4)>0\n",
    "         for _ in range(1,10001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6254"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the exponential function satisfies:\n",
    "\n",
    "$$e^x = \\lim\\limits_{n \\to \\infty} (1 + \\frac{x}{n})^n$$\n",
    "\n",
    "Hence, we can easily see that the probability $P_j$ that the *j*th observation is not in the bootstrap sample is:\n",
    "\n",
    "$$\\begin{align} P_j &= \\lim\\limits_{n \\to \\infty} (1 - \\frac1n)^n \\\\ &= e^{-1} \\end{align}$$\n",
    "\n",
    "Therefore, as $n$ increases, the probability of the *j*th observation being in the bootstrap samples is:\n",
    "\n",
    "$$1 - P_j = 1 - e^{-1} \\approx 0.63212$$.\n",
    "\n",
    "The above demonstrates the often encountered statement about the bootstrap:\n",
    "\n",
    "> On average, each bootstrap sample makes use of around two-thirds of the observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**. We now review *k*-fold cross-validation\n",
    "\n",
    "(a) Explain how *k*-fold cross-validatino is implemented.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "The *k*-fold cross validation is implemented by taking the $n$ observations and randomly splitting it into $k$ non-overlapping groups with the length of (approximately) $n/k$. These groups acts as a validation set, and the remainder (of length n−n/k) acts as a training set. The test error is then estimated by averaging the $k$ resulting *MSE* estimates.\n",
    "\n",
    "(b) What are the advantages and disadvantages of *k*-fold cross-validation relative to:\n",
    "* The validation set approach?\n",
    "* LOOCV?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "i. The validation set approach:\n",
    "\n",
    "The validation set approach has two main drawbacks compared to *k*-fold cross-validation. \n",
    "* First, the validation estimate of the test error rate can be highly variable (depending on precisely which observations are included in the training set and which observations are included in the validation set). \n",
    "* Second, only a subset of the observations are used to fit the model. Since statistical methods tend to perform worse when trained on fewer observations, this suggests that the validation set error rate may tend to overestimate the test error rate for the model fit on the entire data set.\n",
    "\n",
    "ii. LOOCV:\n",
    "\n",
    "The LOOCV cross-validation approach is a special case of k-fold cross-validation in which $k=n$. This approach has two drawbacks compared to k-fold cross-validation. \n",
    "* First, it requires fitting the potentially computationally expensive model $n$ times compared to *k*-fold cross-validation which requires the model to be fitted only $k$ times. \n",
    "* Second, the LOOCV cross-validation approach may give approximately unbiased estimates of the test error, since each training set contains $n−1$ observations; however, this approach has higher variance than *k*-fold cross-validation (since we are averaging the outputs of $n$ fitted models trained on an almost identical set of observations, these outputs are highly correlated, and the mean of highly correlated quantities has higher variance than less correlated ones). \n",
    "\n",
    "So, there is a bias-variance trade-off associated with the choice of $k$ in *k*-fold cross-validation; typically using $k=5$ or $k=10$ yield test error rate estimates that suffer neither from excessively high bias nor from very high variance.\n",
    "\n",
    "**Q4**. Suppose that we use some statistical learning method to make a prediction for the response *Y* for a particular value of the predictor *X*. Carefully describe how we might estimate the standard deviation of our prediction.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "We may estimate the standard deviation of our prediction by using the bootstrap method. In this case, rather than obtaining new independant data sets from the population and fitting our model on those data sets, we instead obtain repeated random samples from the original data set. In this case, we perform sampling with replacement $B$ times and then find the corresponding estimates and the standard deviation of those $B$ estimates by using equation (5.8).\n",
    "\n",
    "# Applied\n",
    "\n",
    "**Q5**. In Chapter 4, we used logitic regression to predict the probability of **default** using **income** and **balance** on the **Default** data set. We will now estimate the test error of this logistic regression model using the validation set approach.\n",
    "\n",
    "(a) Fit a logistic regression model that uses **income** and **balance** to predict **default**.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "1      No      No   729.526495  44361.625074\n",
       "2      No     Yes   817.180407  12106.134700\n",
       "3      No      No  1073.549164  31767.138947\n",
       "4      No      No   529.250605  35704.493935\n",
       "5      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default = pd.read_csv('../data/Default.csv',\n",
    "                     na_values='?',\n",
    "                     index_col=0)\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>['default[No]', 'default[Yes]']</td> <th>  No. Observations:  </th>  <td> 10000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                         <td>GLM</td>               <th>  Df Residuals:      </th>  <td>  9997</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>               <td>Binomial</td>             <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>                <td>logit</td>              <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                       <td>IRLS</td>               <th>  Log-Likelihood:    </th> <td> -789.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                   <td>Wed, 13 Jan 2021</td>         <th>  Deviance:          </th> <td>  1579.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                       <td>22:23:11</td>             <th>  Pearson chi2:      </th> <td>6.95e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>                 <td>9</td>                <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>            <td>nonrobust</td>            <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   11.5405</td> <td>    0.435</td> <td>   26.544</td> <td> 0.000</td> <td>   10.688</td> <td>   12.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td>-2.081e-05</td> <td> 4.99e-06</td> <td>   -4.174</td> <td> 0.000</td> <td>-3.06e-05</td> <td> -1.1e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>   -0.0056</td> <td>    0.000</td> <td>  -24.835</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                        Generalized Linear Model Regression Results                        \n",
       "===========================================================================================\n",
       "Dep. Variable:     ['default[No]', 'default[Yes]']   No. Observations:                10000\n",
       "Model:                                         GLM   Df Residuals:                     9997\n",
       "Model Family:                             Binomial   Df Model:                            2\n",
       "Link Function:                               logit   Scale:                          1.0000\n",
       "Method:                                       IRLS   Log-Likelihood:                -789.48\n",
       "Date:                             Wed, 13 Jan 2021   Deviance:                       1579.0\n",
       "Time:                                     22:23:11   Pearson chi2:                 6.95e+03\n",
       "No. Iterations:                                  9                                         \n",
       "Covariance Type:                         nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     11.5405      0.435     26.544      0.000      10.688      12.393\n",
       "income     -2.081e-05   4.99e-06     -4.174      0.000   -3.06e-05    -1.1e-05\n",
       "balance       -0.0056      0.000    -24.835      0.000      -0.006      -0.005\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_fit = smf.glm('default~income+balance',\n",
    "                 data=default,\n",
    "                 family=sm.families.Binomial()).fit()\n",
    "lg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Using the validation set approach, estimate the test error of this model.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0258"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_test_error(df): \n",
    "    # Split the sample set into a training set and a validation set\n",
    "    df_train = df.sample(frac=0.5)\n",
    "    df_test = df[~df.isin(df_train)].dropna(how='all')\n",
    "    # Fit a multiple logistic regression model using only the training observations\n",
    "    lg_fit = smf.glm('default~income+balance',\n",
    "                     data=df,\n",
    "                     family=sm.families.Binomial(),\n",
    "                     subset=df_train.index).fit()\n",
    "    # Obtain a prediction of default status for each individual in the validation set.\n",
    "    lg_prob = lg_fit.predict(df_test)\n",
    "    lg_pred = np.where(lg_prob>0.5, 'No', 'Yes')\n",
    "    # Compute the validation set error\n",
    "    return (lg_pred != df_test['default']).mean()\n",
    "\n",
    "get_test_error(default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a $2.74\\%$ test error with the validation set approach.\n",
    "\n",
    "(c) Repeate the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0: 0.03\n",
      "No.1: 0.0308\n",
      "No.2: 0.0256\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f'No.{i}: {get_test_error(default)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the validation estimate of the test error rate can be variable, depending on precisely which observations are included in the training set and which observations are included in the validation set.\n",
    "\n",
    "(d). Now consider a logistic regression model that predicts the probability of **default** using **income**, **balance**, and a dummy variable for **student**. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for **student** leads to a reduction in the test error rate.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0248"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_train = default.sample(frac=0.5)\n",
    "default_test = default[~default.isin(default_train)].dropna(how='all')\n",
    "\n",
    "lg_fit = smf.glm('default~income+balance+C(student)',\n",
    "                 data=default,\n",
    "                 family=sm.families.Binomial(),\n",
    "                 subset=default_train.index).fit()\n",
    "lg_prob = lg_fit.predict(default_test)\n",
    "lg_pred = np.where(lg_prob>0.5, 'No', 'Yes')\n",
    "\n",
    "(lg_pred != default_test['default']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem that adding the \"student\" dummy variable leads to a reduction in the validation set estimate of the test error rate.\n",
    "\n",
    "**Q6**. We continue to consider the use of a logistic regression model to predict the probability of **default** using **income** and **balance** on the **Default** data set. In particular, we will now compute estimates for the standard errors of the **income** and **balance** logistic regression coefficients in two different ways: (1) using the bootstrap, and (2) using the standard formular for computing the standard errors in the `glm()` function.\n",
    "\n",
    "(a) Using the `summary()` method and `glm()` funtion, determine the estimated standard errors for the coefficients associated with **income** and **balance** in a multiple logistic regression model that uses both predictors.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>['default[No]', 'default[Yes]']</td> <th>  No. Observations:  </th>  <td> 10000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                         <td>GLM</td>               <th>  Df Residuals:      </th>  <td>  9997</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>               <td>Binomial</td>             <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>                <td>logit</td>              <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                       <td>IRLS</td>               <th>  Log-Likelihood:    </th> <td> -789.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                   <td>Wed, 13 Jan 2021</td>         <th>  Deviance:          </th> <td>  1579.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                       <td>22:23:12</td>             <th>  Pearson chi2:      </th> <td>6.95e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>                 <td>9</td>                <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>            <td>nonrobust</td>            <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   11.5405</td> <td>    0.435</td> <td>   26.544</td> <td> 0.000</td> <td>   10.688</td> <td>   12.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td>-2.081e-05</td> <td> 4.99e-06</td> <td>   -4.174</td> <td> 0.000</td> <td>-3.06e-05</td> <td> -1.1e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>   -0.0056</td> <td>    0.000</td> <td>  -24.835</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                        Generalized Linear Model Regression Results                        \n",
       "===========================================================================================\n",
       "Dep. Variable:     ['default[No]', 'default[Yes]']   No. Observations:                10000\n",
       "Model:                                         GLM   Df Residuals:                     9997\n",
       "Model Family:                             Binomial   Df Model:                            2\n",
       "Link Function:                               logit   Scale:                          1.0000\n",
       "Method:                                       IRLS   Log-Likelihood:                -789.48\n",
       "Date:                             Wed, 13 Jan 2021   Deviance:                       1579.0\n",
       "Time:                                     22:23:12   Pearson chi2:                 6.95e+03\n",
       "No. Iterations:                                  9                                         \n",
       "Covariance Type:                         nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     11.5405      0.435     26.544      0.000      10.688      12.393\n",
       "income     -2.081e-05   4.99e-06     -4.174      0.000   -3.06e-05    -1.1e-05\n",
       "balance       -0.0056      0.000    -24.835      0.000      -0.006      -0.005\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_fit = smf.glm('default~income+balance',\n",
    "                 data=default,\n",
    "                 family=sm.families.Binomial()).fit()\n",
    "lg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `glm()` estimates of the standard errors for the coefficients $\\beta_0$, $\\beta_1$ and $\\beta_2$ are 0.435, 4.99^-6, and almose zero, respectively.\n",
    "\n",
    "(b) Write a function, `coef()`, that takes as input the **Default** data set, and that outputs the coefficients estimates for **income** and **balance** in the multiple logistic regression model.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef(df):\n",
    "    lg_fit = smf.glm('default~income+balance',\n",
    "                      data=df,\n",
    "                      family=sm.families.Binomial()).fit()\n",
    "    return lg_fit.params.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Use the `boot()` function together with the `coef()` function to estimate the standard errors of the logistic regression coefficients for **income** and **balance**.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot(df, fun, n):\n",
    "    tresult = [fun(df.sample(frac=1, replace=True))\n",
    "               for _ in range(n)]\n",
    "    estimate = sum(tresult)/n\n",
    "    std_est = np.std(tresult, axis=0)\n",
    "    print('Bootstrap Statistics:\\n'\n",
    "         f'Estimate: {estimate}\\n'\n",
    "         f'STD: {std_est}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Statistics:\n",
      "Estimate: [ 1.15743244e+01 -2.09242269e-05 -5.66143917e-03]\n",
      "STD: [4.20008591e-01 4.83414823e-06 2.22147678e-04]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boot(default, coef, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Comment on the estimated standard errors obtained using the `glm()` function and using your bootstrap function.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "The estimated standard errors for the coefficients $\\beta_0$, $\\beta_1$, $\\beta_2$ are $0.456$, $4.95e-6$, $2.36e-4$, respectively. We can see that the estimated standard errors are close to those given by `glm()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7**. In this exercises, we use the `glm()` and `predict()` functions, and a `for` loop to compute the LOOCV test error estimate for a simple logistic regression model on the **Weekly** data set. \n",
    "\n",
    "(a) Fig a logistic regression model that predicts **Direction** using **Lag1** and **Lag2**.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
       "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
       "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
       "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up\n",
       "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up\n",
       "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly = pd.read_csv('../data/Weekly.csv',\n",
    "                     na_values='?')\n",
    "weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>['Direction[Down]', 'Direction[Up]']</td> <th>  No. Observations:  </th>  <td>  1089</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                            <td>GLM</td>                 <th>  Df Residuals:      </th>  <td>  1086</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>                  <td>Binomial</td>               <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>                   <td>logit</td>                <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                          <td>IRLS</td>                 <th>  Log-Likelihood:    </th> <td> -744.11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                      <td>Wed, 13 Jan 2021</td>           <th>  Deviance:          </th> <td>  1488.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                          <td>22:26:15</td>               <th>  Pearson chi2:      </th> <td>1.09e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>                    <td>4</td>                  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>               <td>nonrobust</td>              <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.2212</td> <td>    0.061</td> <td>   -3.599</td> <td> 0.000</td> <td>   -0.342</td> <td>   -0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>      <td>    0.0387</td> <td>    0.026</td> <td>    1.477</td> <td> 0.140</td> <td>   -0.013</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>      <td>   -0.0602</td> <td>    0.027</td> <td>   -2.270</td> <td> 0.023</td> <td>   -0.112</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Generalized Linear Model Regression Results                           \n",
       "================================================================================================\n",
       "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1089\n",
       "Model:                                              GLM   Df Residuals:                     1086\n",
       "Model Family:                                  Binomial   Df Model:                            2\n",
       "Link Function:                                    logit   Scale:                          1.0000\n",
       "Method:                                            IRLS   Log-Likelihood:                -744.11\n",
       "Date:                                  Wed, 13 Jan 2021   Deviance:                       1488.2\n",
       "Time:                                          22:26:15   Pearson chi2:                 1.09e+03\n",
       "No. Iterations:                                       4                                         \n",
       "Covariance Type:                              nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.2212      0.061     -3.599      0.000      -0.342      -0.101\n",
       "Lag1           0.0387      0.026      1.477      0.140      -0.013       0.090\n",
       "Lag2          -0.0602      0.027     -2.270      0.023      -0.112      -0.008\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_fit = smf.glm('Direction~Lag1+Lag2',\n",
    "                 data=weekly,\n",
    "                 family=sm.families.Binomial()).fit()\n",
    "lg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Fit a logistic regression model that predicts **Direction** using **Lag1** and **Lag2** *using all but the first observation*.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>['Direction[Down]', 'Direction[Up]']</td> <th>  No. Observations:  </th>  <td>  1088</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                            <td>GLM</td>                 <th>  Df Residuals:      </th>  <td>  1085</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>                  <td>Binomial</td>               <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>                   <td>logit</td>                <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                          <td>IRLS</td>                 <th>  Log-Likelihood:    </th> <td> -743.26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                      <td>Wed, 13 Jan 2021</td>           <th>  Deviance:          </th> <td>  1486.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                          <td>22:26:15</td>               <th>  Pearson chi2:      </th> <td>1.09e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>                    <td>4</td>                  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>               <td>nonrobust</td>              <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.2232</td> <td>    0.061</td> <td>   -3.630</td> <td> 0.000</td> <td>   -0.344</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>      <td>    0.0384</td> <td>    0.026</td> <td>    1.466</td> <td> 0.143</td> <td>   -0.013</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>      <td>   -0.0608</td> <td>    0.027</td> <td>   -2.291</td> <td> 0.022</td> <td>   -0.113</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Generalized Linear Model Regression Results                           \n",
       "================================================================================================\n",
       "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1088\n",
       "Model:                                              GLM   Df Residuals:                     1085\n",
       "Model Family:                                  Binomial   Df Model:                            2\n",
       "Link Function:                                    logit   Scale:                          1.0000\n",
       "Method:                                            IRLS   Log-Likelihood:                -743.26\n",
       "Date:                                  Wed, 13 Jan 2021   Deviance:                       1486.5\n",
       "Time:                                          22:26:15   Pearson chi2:                 1.09e+03\n",
       "No. Iterations:                                       4                                         \n",
       "Covariance Type:                              nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.2232      0.061     -3.630      0.000      -0.344      -0.103\n",
       "Lag1           0.0384      0.026      1.466      0.143      -0.013       0.090\n",
       "Lag2          -0.0608      0.027     -2.291      0.022      -0.113      -0.009\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = weekly.index.difference([0])\n",
    "lg_fit = smf.glm('Direction~Lag1+Lag2',\n",
    "                 data=weekly,\n",
    "                 family=sm.families.Binomial(),\n",
    "                 subset=train).fit()\n",
    "lg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Use the model from (b) to predict the direction of the first observation. Was this observation correctly classified?\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the first observation is Up ,\n",
      "while the true value is Down\n"
     ]
    }
   ],
   "source": [
    "y_prob = lg_fit.predict(weekly.iloc[[0]])\n",
    "print('Prediction for the first observation is',\n",
    "      'Down' if y_prob[0] > 0.5 else 'Up',\n",
    "      ',\\nwhile the true value is',\n",
    "      weekly['Direction'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this observation is not correctly classified.\n",
    "\n",
    "(d) Write a for loop form $i=1$ to $i=n$, where $n$ is the number of observations in the data set, that performs each of the following steps:\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_num = 0\n",
    "for i in range(len(weekly)):\n",
    "    # Fit a logistic regression model using all but the \n",
    "    # ith observation for predictions\n",
    "    train = weekly.index.difference([i])\n",
    "    lg_fit = smf.glm('Direction~Lag1+Lag2',\n",
    "                     data=weekly,\n",
    "                     family=sm.families.Binomial(),\n",
    "                     subset=train).fit()\n",
    "    # Compute the posterior probability of the market\n",
    "    # moving down for the ith observation\n",
    "    y_prob = lg_fit.predict(weekly.iloc[[0]])[0]\n",
    "    # Use the posterior probability to make a prediction\n",
    "    y_pred = 'Down' if y_prob >= 0.5 else 'Up'\n",
    "    # Determine whether or not an error was made in predicting\n",
    "    # the direction for the ith observation\n",
    "    if y_pred != weekly['Direction'][i]:\n",
    "        error_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Take the average of the $n$ numbers obtained in (d) in order to obtain the LOOCV estimate for the test error. Comment on the results.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_num / len(weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LOOCV estimate for the test error is 44.44%.\n",
    "\n",
    "**Q8**. We will now perform cross-validation on a simulated data set.\n",
    "\n",
    "(a) Generate a simulated data set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.normal(size=100)\n",
    "y = x - 2*x**2 + np.random.normal(size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set, what is $n$ and what is $p$? Write out the model used to generate the data in equation form.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "Here we have $n = 100$, and $p=2$ (because $x^2$ is actually a new feature). The equation form is:\n",
    "\n",
    "$$y = X - 2 \\cdot X^2 + \\epsilon$$\n",
    "\n",
    "(b) Create a scatterplot of $X$ against $Y$. Comment on what you find.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgCUlEQVR4nO3df3TcdZ3v8ed7QtrQ9HeaprUlDVkKlB/dwkasLnWPBdnKZRcpC6Ln4uqiOdcjFMVdWUX2nntkPVb3dpcu3F2rsN5Fd6EeRFRqkR/eI9wLagqFUkppiW0ptiUEbJuUadPO+/6RTJjMdyaZmczM9zszr8c5HDrznU7fmSSf9/fz/vwyd0dERCRVLOwAREQkepQcREQkQMlBREQClBxERCRAyUFERAJOCjuAYpg1a5a3tbWFHYaISEXZtGnTG+7enOlaVSSHtrY2urq6wg5DRKSimNnubNdUVhIRkQAlBxERCVByEBGRACUHEREJUHIQEZGAqpitJFJtEglnV28/Bw7FaZnaQFtTI7GYhR2W1BAlB5GISSScjVv3c9P6zcQHEjTUx1hz9RJWnD1HCULKRmUlkYjZ1ds/nBgA4gMJblq/mV29/SFHJrVEyUEkYg4cig8nhqT4QILXD8dDikhqkZKDSMS0TG2goX7kr2ZDfYzZUxpCikhqkZKDSMS0NTWy5uolwwkiOebQ1tQYcmRSSzQgLRIxsZix4uw5nLlqGa8fjjN7imYrSfkpOYhEUCxmtDdPpr15ctihSI2KZFnJzE4xs1+Y2YtmttXMbgw7JhGRWhLVnsNx4Avu/oyZTQE2mdkj7v5i2IGJVDotsJNcRDI5uPs+YN/Qnw+b2TZgHqDkIDIOWmAnuYpkWSmVmbUB5wG/Snu+08y6zKyrp6cnlNhEKo0W2EmuIp0czGwycD/wOXc/lHrN3de5e4e7dzQ3ZzzlTkTSaIGd5CqyycHM6hlMDN939x+GHY9INdACO8lVJJODmRlwF7DN3deEHY/UhkTC6e7p46lX3qC7p49EwsMOqei0wE5yFckBaeCPgWuBLWa2eei5L7v7hvBCkmo23oHaSpkBpAV2kqtIJgd3fxLQT6uUTbaB2jNXLRtzIVqlzQDSAjvJRSTLSiLlNp6B2ijOAKqFEpmUViR7DiLllEg4kybUseqi00g43L9pL/sOxnMeqB0tsYRxd15pPRmJJiUHqWmZGtJVyxdyX9cebl6xKKeB2uQMoNQEMVZiKeUYxXhKZCJJKitJTcvUkK59fAdrrzkv5zvtfGcAJRPSpWuf4KPf/hWXrn2CjVv3F630o7UMUgzqOUhNy9aQvj1wIuc7+XxnAJX6zr6QnoxIOvUcpKYVa1FYcgbQ0vZZtDdPHjWxlPrOXmsZpBjUc5CalmxI0wdvW2dMorunryRjAqW+s8+1J1MpazMkHOZe+VPcOjo6vKurK+wwpEIlG8lkQ9o6YxI/33agZLN9CplNVOyGPN8YlEiqk5ltcveOjNeUHERG6u7p49K1TwTu7DcUcbZPekIarbEtdGrqaA16Pl+jpsZWr9GSg8YcRNKUY7ZPLmMUyYVs/+fl19m+/xAzJk0YjmWsRXZjzYjK52uM4iI/KT0lB5E05di5dKwVzKmN+199t4tv/bKba5cuYO60wRjGSlZjNeijfY3psY0nWWqlduXSgLRImmyD1MWa7ZNIOI9vP8Dzew+ScKgzOHf+NJaf0TLcg9jV28/qjdu47sJ2bKhTcV/XHlaeP587f7FzzGSVrUE/cCg+fP3b13bwlQe3sLv37RED8eklpG9f21HQALrKUZVNyUEkTal3Lt3zZj87DvSx7pfdw43mjRctZOHsyZxIDDbcE+pifOyCBfzjoy+PWLkdi+U2NTXbjKiBEz481tBQH2P1lYuZN72BmY0TaWtqzNjj+MqDW1h95WJuvv/5vJKlVmpXNiUHkTSlnplz4NBRbn9sx4hG8/bHdnDm3Kl85nubiA8kWHXRacPJI/matY/v4N8/eQEbVi3LGlMy9t7+o4EGffWVi7n1wS0j3vPm+58ffr9dvf28fOBwoMexu/dt5k1vYEOeyTJqe05JfpQcRFKUoxTSf+x4xkbz2T1vDT+fcDK+5oR71oY1PfYFTSez7toO6uuMlqkN9PYfZXfv24H3PHAozkv7D3PT+s18all7xh7HzMaJeW/zrZXalU0D0iIpxhrILcYA64KZjRkHg0+MzAWjDoon4/jNrl6ee/UtnnrlDba89vsRse/ufZvOe7pomdpAe/NkmhonZnzPo8cTrN64jfhAgvs37WXV8oVFWV2tldqVTT0HkRSjlULamhqL0qs4dVZwwPtrV5zL7Y+9PPya+zft5caLFg6Xn5LjEr/t7WPBzMFFeqs3buMjHa2sfXzHcClqtDJOW1NjoNS0avlC/vuPX+CyxfO48xc72Xcwzj1P7+a6C9tZPG8qC1umFFxW06lzlS2yycHMVgC3A3XAd9z96yGHJFVurHMdkr2KGZMmsPL8+ZjB9v2HOGvuFNpm5V5uydRo1sXgmne3DieDt44co3FCHXd89Dx6+44xaeJJvPb7I3z1py/SfM1Eblq/mesubB9ODDBYihqtjBOLGe+a3jA8A8od7nl6N/sOxqlL6VDsOxjnrie7i7LoT6fOVa5IJgczqwPuBD4I7AV+Y2Y/dvcXw41MqlUu5zr86re9zJg0gWuXLhhulBvqYyxoaqR1Zn53xOmNZiLhLGyZTOf720k4xAzmTj+ZV3r6AzOWevuPEh9IYDZyXCJZEkqNLb2M09Q4kbue7A4kkI4FM4cTi8o/AhFNDsAFwE537wYws3uBywElBwkYbXZRrjOPsp3rcF/nUs6dN51YbHBQ96qO+SPu1uMDCb78wBaWnDJ9XHfHsZix/IwW2mdNHu5N9MUHuOE/nw3E9L3r3jOijp+8vu9gnPu69nBf51LeHjiRsYyTbQ3H+9qb8p6NJNUtqslhHvBqyuO9wHtSX2BmnUAnQGtra/kik0gZbXYRkPMYQS7nOrQ1NXL67Cklm56Z3pt46pU3Mv5bAycSrLl6Cas3bgv0FG5YvpCz507jpJMyzzXJNg6QVAVbrUmRRDU5jMnd1wHrYHDjvZDDkZCMttAKyHkRVi7TLmMxY9HcqRlfd3J9HYmE591jGU22mFqmNvDuBTOZNKGOl/cf4ht/8Yfs6e2nvXkydz/5Cue3zhg1UWUqaWmHVkkX1eTwGnBKyuP5Q89JjUttmOZOa+CNvqN8alk78M4AcvJO3rOsFch0lz/WlhnJf/fNI8HFZauWL2TVvc9y84pFefdYRjNaTLt6+/lvQwvmkhrqY1x3YXvevZh8VjJrS4zaEdXk8BtgoZmdymBSuAb4WLghSdhSG6YZkybw8fcuGDHVc9Xyhdzz9G7eOnJs+I4/10VYo027zLS47H9/8gJ29/Zz8oTBWUTHjntBPZbRjBZTtjJYXYy8F5nls5K5nFtiqIcSrkgmB3c/bmbXAw8zOJX1bnffGnJYErLUhmnl+fMDW1CsfXwHne9v58w5U4fv+PPZQC/btMv0BvHYcWdnTx9f/emLgcSUb48lVbbGMFNM2UpOHQtm5j3LKJ+VzOXaEiNbD+WSRS3seeuIEkYZRDI5ALj7BmBD2HFIdKQ2TKnTOOdOaxhed7C0fSYXLGgabjCKsQgrvUFcef784cQAIxPTaD2Wk+vreOqVNzI2avmWazKVnFZfuZj3tTfl/fXlswttubbEyNRDWb1xGwMnEoENAFXSKo3IJgeRdOkNU0N9LLDu4DtPjJytVIyyRPq/m76+AAYfnz60mhiCPZbbPnwOq+59dsT22KmNWr7lmmKuPs7nvZKJZPXGbVy2eB51MXj3gpm0zpgEFK8UlKmHctniecOJAbTLa6kpOUjFSG2YGifUcetlZ3HgUDyw7uCm9Zs544ZlbD9wuOCB09RGbvaUBu742Hlc/x+Daw7qLHPPYNGcqRl7LCfX1w0nhtQYUxu1Qso1xVx9nOt7xWLGJYtaMt7BX7KopWhnb2fqodTFCivXSWG08Z5UjGTDdNMHz+D2x3Zwx+M7mTf95IwNxp43Cz/aMv2Izf/yz09w7Liz8cZl3Nv5Hq44b17GDeVOnfVOGSb1GNAjx05k3A019SS1cpw+Vyx73jqS8Q7+xX0HeWn/IT61rJ3rl5/GjEkTCj5ONNOmfe8eWsWdKqqfUTVQz0EqSmrDtO9gnFffejvjXfykCScVfJeZrcSzYdUylrbPAqB1ZmPOJZ1c6vSlPn2umLL1cnb1HhlxgNGtl53F4fgAPX1HaZ0xKa+B5EylrtYZkyrmM6oGSg4Saek17N7+oyM2vps8sY7PX3z6iP2H1ly9hJapEwseOM2lxJNPSSeXhj+Xun9UpnZmS3Y7e/pGJNSv/vRFrruwnb+8+9fc9uFz+OfHd2Qdc8kk02esXV7Lx7wK1st3dHR4V1dX2GFIkWWawfNPH1nCnjePsOaRd5LBlz90JktOmc6RlP2EoPCFaN09fcNHaSY11MfGtUtpsmEvtFGL0uKzTLF87Ypz+ebD29l3MD7itdcvP407Ht85vEDvzl/sBHL/PKOSEKuVmW1y945M19RzkMjKVN55cd+hwPGZX/vZSzx0wzIWnzJjxN8v9C6zFCWe8Q4eR+k85ky9nJjBW0eOjXhdQ31seK+m+MDgLrJJua77iEpCrEVKDhJZmco72Y7P7OmL8wezRzY0hTbIUTykJmrnMWfanyk9oSYXBsLIRJF8PFaJL0oJsRYpOUhkZZzOmGUaafrGd7nKVraI2iE1UT+POTWhHjgUZ+CEc+uDW4YPS0qOOUDux4VGLSHWGiUHiaxM5Z1z50/LeIeauvFdrgmiksoWlTCbKTWhJhLOv33ighEzjc5vnZFXTyzqCbHaaUBaIi3TQC7Altd+z2Mvvc6JBPzwmXeO88xn0LgUA8+lNN5B7Upz/HiC/9fdS9fuN0k4/OS51/K+AZDRaUBaKla28s6RYydY+9jOEc/lW3LIVrY4cKh8ZYt8ZuNErdRVSomEB1Zbr75yMZcsalFiKBMlB6lIxSg5ZHuPgRM+PH6R3njnu5hrNJVU1iq3TIPRN9//POfOm1YTyTEKtH2GhC6RcLp7+njqlTfo7ukjkRi71Jlpe4V8a/BtTY2svnLxiPdYtXwhtz64hV29/YFtND753V/zo+deG3586don2Lh1f07xZpJtNk4h201ESSHfz3SjDUZLeajnIKEq9O65GNNNYzHjXdMbuO7CdswGz0++5+nd7DsYH26EUhvvyxbP4ys/eqFoUyurcTZO+oFMV3XM5/TZU1g0dyqnzsr9+6PB6PApOUio8p3LnqlGP56GtKlxInc92Z2xEUpvvLNt1V1oY16NDWDy+5m+lXq+JbNKmJ1V7VRWklDlUz5IL/OMt6wDo5ensu2Umv640Ma8GKWxqEl+P1eePz/jVuq5lsySPcMNqwZ3wt2wapnGYsoscj0HM/sm8GfAMeAV4JPu/vtQg5KSyefuuRQrZkcrT6Xfvf7kude47cPnDJeWxtuYR3El9nglv5/F6GXV0uysKIpccgAeAb40dI70auBLwM0hxyQlkk/5oFQ1+myNULZto/NdzFXIv12pkt/P7fsPVV3JrNZELjm4+89THj4N/EVYsUjp5XP3HEaNPlPjXU2NebElv59nzZ3CgqZGvvzAFo0ZVKhIr5A2s58A97n79zJc6wQ6AVpbW/9o9+7d5Q5PykzrAipLMVZ0a8vu0hpthXQoycHMHgXmZLh0i7s/OPSaW4AOYKWPEaS2z6gMxfhFr7UtJGqZbgZKL3LbZ7j7xaNdN7NPAJcBF42VGKQyFPKLni2ZqKxTG7Rld7giN5XVzFYAXwT+3N2PhB2PFEe+q4FLMW1VKotWSYcrcskBuAOYAjxiZpvN7F/DDkjGL/0Xfe60wZXJLx84nHGLhWrdWqLWjGcrjWzrTDTjqTyiOFvptLBjkOJLnWk0d1rDmKtnq3FriVoz3jEDrZIOVxR7DhJx490oL5fVs7prrHzj7f1plXS4ItdzkGjLdjd4yaKWUbeyTl3P8PKBw2P2CnTXWPmK0fvTBITwKDlIXrLdDa67toPOe7pGLR8kf9Eh8znQqb2CWMy4ZFEL93UuZd/BOHOnNXD23GnA4AlumvcefeVYtFisdRBaTxGk5CB5yXY32LX7zZynHObSK8h0EtgdHzuPY8dd894rRKl7f8VaB6H1FJkpOUhest0NnhiZL0YtH+SyZUamHsrzew+y7pfdOSehfOnusbhKvbFgsdZB5Po+tfbzoeQgecl0N3jbh8/lzb7B0s++g4Nz0McqH4xVS87UQ0l4cc9TGPHeunssiVKOGRRrRlsu71OLPx+arSR5Sd4NPnTDMu742Hl0vr+d//nz7ax5dAcff+8C5k5rKEr5INNspTor7nkKqbSuovIUa0ZbLu9Tiz8fSg6St1jMMIO//sFzrH1sJ/sODt553f7YDv7pI0uKMuUw00E4586fVrLDcbQat/IU67CkXN4n9edj7rQGPvuB0/jUsnZ6+o5W7ap9lZWkINkaU8eLUkLIVq8GSlLDrsYjO6tdscY0cnmf5M9H+vGn33miu2rLS5HesjtX2pW1/Lp7+rh07ROBxnRDhW6KVos1Zcld8ufjpf2HRkyKgMr+uY/crqxS+aptkVo1HtkpxZP8+UjvXUL1buui5CAFSf6ynHHDMva82c+kCSfRMnVi2GGNi1bjymiS54rXSvlRA9IyLtsPHOYz33+Gj6x7mhW3a1ttqW7ZBq9jRkE7z0aZxhykYNU27iCSi9TTCJsnN/Db3j6u/49nK3KsarQxB/UcpGCa/im1KFl+XNo+CzOGEwNU1/oHJQcpmLbVllpXzTdIkU0OZvYFM3MzmxV2LJJZsRYhiVSqar5BiuRsJTM7BbgE2BN2LJLdeKd/1tpGZlJ9qm1Kd6pIJgfgH4EvAg+GHYiMrtDpn1p0JpVitJuYal4fE7nkYGaXA6+5+3Nmlf8BS2bF2m5ZpBC59lpzuYmp1vUxoSQHM3sUmJPh0i3AlxksKY31Hp1AJ0Bra2tR45PSK9Z2yyL5yqfXWss3MaEMSLv7xe5+Tvp/QDdwKvCcme0C5gPPmFkgkbj7OnfvcPeO5ubm8n4BMm7VPJAn0ZbP9tvVPBtpLJGareTuW9x9tru3uXsbsBc43933hxyaFJlmOklY8mnwa/kmJnJjDlIbqnkgT6Itn+3Zq3k20li0fYaI1JR8Z8qlbpdRbTcxo22foeQgIjWnmhv8fOg8BxGRFNU6/bSYlBxkXLTKWaQ6KTlIwbTKWaR6RWoqq1SWfOaLi0hlUXKQgtXyAiGRapc1OZjZBjNrK2MsUmFqeYGQSLUbrefwb8DPzewWM6svV0BSObTKWSQ8iYTT3dNXsrOrsw5Iu/sPzOxnwK1Al5ndAyRSrq8paiRScbTKWSQc5ZgMMtaYwzGgH5gITEn7T2TEebrtzZOVGETKoByTQbL2HMxsBbAG+DGDm98dKdq/KiIiBSvHlvejrXO4BbjK3bcW5V8SEZGiyGfzwEJlLSu5+zIlBhGR6CnHZBCtkBYRqTDlmAyi5CAiUoFKvXmgVkiLiEiAkoOIiAREMjmY2Q1m9pKZbTWzb4Qdj4hIrYncmIOZfQC4HPhDdz9qZrPDjklEpNZELjkAnwG+7u5HAdz99ZDjEREJTVgHakUxOZwOLDOzvwfiwF+7+2/SX2RmnUAnQGtra3kjFBEpgzAP1AplzMHMHjWzFzL8dzmDCWsmsBT4G2C9mQU+BXdf5+4d7t7R3Nxc5q+gspR690YRKY0wD9QKpefg7hdnu2ZmnwF+6O4O/NrMEsAsoKdc8VUTHeUpUrnKsYdSNlGcrfQj4AMAZnY6MAF4I8yAKpmO8hSpXGEeqBXF5HA30G5mLwD3An851IuQAugoT5HKFeaBWpEbkHb3Y8B/DTuOalGO3RtFpDTCPFArij0HKSId5SlS2cI6UCtyPQcpLh3lKSKFUHKoAaXevVFEqo/KSiIiEqDkICIiAUoOIiISoOQgIiIBGpCuMWHt8CgilUXJoYZonyURyZXKSjVE+yyJSK6UHGqI9lkSkVwpOdSQMHd4FJHKouRQQ7TPkojkSgPSNUT7LIlIrpQcaoz2WRKRXKisJCIiAUoOIiISELnkYGZLzOxpM9tsZl1mdkHYMYmI1JrIJQfgG8D/cPclwN8NPRYRkTKKYnJwYOrQn6cBvwsxFhGRmhTF2UqfAx42s39gMHm9L9OLzKwT6ARobW0tW3AiIrUglORgZo8CczJcugW4CPi8u99vZlcDdwEXp7/Q3dcB6wA6Ojq8hOGKiNScUJKDuwca+yQz+3fgxqGHPwC+U5agRERkWBTHHH4H/MnQn5cDO0KMRUSkJkVxzOHTwO1mdhIQZ2hcQUREyidyycHdnwT+KOw4RERqWRTLSiIiEjIlBxERCVByEBGRACUHEREJUHIQEZEAJQcREQlQchARkQAlBxERCVByEBGRACUHEREJUHIQEZEAJQcREQlQchARkQAlBxERCVByEBGRACUHEREJUHIQEZGAUJKDmV1lZlvNLGFmHWnXvmRmO81su5n9aRjxiYjUurCOCX0BWAl8K/VJMzsLuAY4G3gX8KiZne7uJ8ofoohI7Qql5+Du29x9e4ZLlwP3uvtRd/8tsBO4oLzRiYhI1MYc5gGvpjzeO/RcgJl1mlmXmXX19PSUJbh0iYTT3dPHU6+8QXdPH4mEhxKHiEixlaysZGaPAnMyXLrF3R8c7/u7+zpgHUBHR0fZW+VEwtm4dT83rd9MfCBBQ32MNVcvYcXZc4jFrNzhiIgUVcmSg7tfXMBfew04JeXx/KHnImdXb/9wYpg7rYGV58/npf2HmDf9ZM6dN00JQkQqWtTKSj8GrjGziWZ2KrAQ+HXIMWV04FB8ODFcu3QBdz3ZzdrHdvKRdU+xcet+lZhEpKKFNZX1CjPbC7wXeMjMHgZw963AeuBFYCPw2ajOVGqZ2kBDfYyV589n7eM7iA8kAIgPJLhp/WZ29faHHKGISOHCmq30gLvPd/eJ7t7i7n+acu3v3f0P3P0Md/9ZGPHloq2pkTVXL6EuxnBiSIoPJHj9cDykyERExi9qZaWKEYsZK86ew0VnttBQP/JjbKiPMXtKQ0iRiYiMn5LDOMRixrnzprHm6iXDCSI5a6mtqTHk6EREChfWCumqkexBnLlqGa8fjjN7SgNtTY2arSQiFU3JoQhiMaO9eTLtzZPDDkVEpChUVhIRkQAlBxERCVByEBGRACUHEREJUHIQEZEAJQcREQlQchARkQAlBxERCVByEBGRACUHEREJUHIQEZEAJQcREQkI6yS4q8xsq5klzKwj5fkPmtkmM9sy9P/lYcQnIlLrwtqV9QVgJfCttOffAP7M3X9nZucADwPzyh2ciEitCyU5uPs2ADNLf/7ZlIdbgZPNbKK7Hy1jeCIiNS/KYw5XAs8oMYiIlF/Jeg5m9igwJ8OlW9z9wTH+7tnAauCSUV7TCXQCtLa2jiNSERFJV7Lk4O4XF/L3zGw+8ADwcXd/ZZT3XwesA+jo6PCCghQRkYwiVVYys+nAQ8Dfuvv/DTkcEZGaFdZU1ivMbC/wXuAhM3t46NL1wGnA35nZ5qH/ZocRo4hILQtrttIDDJaO0p+/Dbit/BGJiEiqSJWVREQkGsJaBBcJiYSzq7efA4fitExtoK2pkVjMxv6LIiJVrmaTQyLhbNy6n5vWbyY+kKChPsaaq5ew4uw5ShAiUvNqtqy0q7d/ODEAxAcS3LR+M7t6+0OOTEQkfDWbHA4cig8nhqT4QILXD8dDikhEJDpqNjm0TG2goX7kl99QH2P2lIaQIhIRiY6aTQ5tTY2suXrJcIJIjjm0NTWGHJmISPhqdkA6FjNWnD2HM1ct4/XDcWZP0WwlEZGkmk0OMJgg2psn0948OexQREQipWbLSiIikp2Sg4iIBCg5iIhIgJKDiIgEKDmIiEiAuVf+IWpm1gPsDjuOFLOAN8IOIkL0eYykz+Md+ixGKvfnscDdmzNdqIrkEDVm1uXuHWHHERX6PEbS5/EOfRYjRenzUFlJREQClBxERCRAyaE01oUdQMTo8xhJn8c79FmMFJnPQ2MOIiISoJ6DiIgEKDmIiEiAkkOJmNk3zewlM3vezB4ws+lhxxQmM7vKzLaaWcLMIjFVr9zMbIWZbTeznWb2t2HHEyYzu9vMXjezF8KOJQrM7BQz+4WZvTj0e3Jj2DEpOZTOI8A57r4YeBn4UsjxhO0FYCXwy7ADCYOZ1QF3Ah8CzgI+amZnhRtVqL4LrAg7iAg5DnzB3c8ClgKfDfvnQ8mhRNz95+5+fOjh08D8MOMJm7tvc/ftYccRoguAne7e7e7HgHuBy0OOKTTu/kvgzbDjiAp33+fuzwz9+TCwDZgXZkxKDuXxV8DPwg5CQjUPeDXl8V5C/uWXaDKzNuA84FdhxlHTJ8GNl5k9CszJcOkWd39w6DW3MNhl/H45YwtDLp+HiGRnZpOB+4HPufuhMGNRchgHd794tOtm9gngMuAir4EFJWN9HjXuNeCUlMfzh54TAcDM6hlMDN939x+GHY/KSiViZiuALwJ/7u5Hwo5HQvcbYKGZnWpmE4BrgB+HHJNEhJkZcBewzd3XhB0PKDmU0h3AFOARM9tsZv8adkBhMrMrzGwv8F7gITN7OOyYymlocsL1wMMMDjaud/et4UYVHjP7T+Ap4Awz22tm14UdU8j+GLgWWD7UXmw2s0vDDEjbZ4iISIB6DiIiEqDkICIiAUoOIiISoOQgIiIBSg4iIhKg5CBSAkO7bP7WzGYOPZ4x9Lgt5NBEcqLkIFIC7v4q8C/A14ee+jqwzt13hRaUSB60zkGkRIa2Q9gE3A18Glji7gPhRiWSG+2tJFIi7j5gZn8DbAQuUWKQSqKykkhpfQjYB5wTdiAi+VByECkRM1sCfJDBk70+b2Zzw41IJHdKDiIlMLTL5r8wuC//HuCbwD+EG5VI7pQcRErj08Aed39k6PH/AhaZ2Z+EGJNIzjRbSUREAtRzEBGRACUHEREJUHIQEZEAJQcREQlQchARkQAlBxERCVByEBGRgP8PGVChMpkHwsMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(x=x, y=y);\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure shows a curved pattern which is similar to a quadratic curve.\n",
    "\n",
    "(c) Set a random seed, and then compute the LOOCV errors that result from fitting the following four models using least squares:\n",
    "\n",
    "i. $Y = \\beta_0 + \\beta_1 X + \\epsilon$\n",
    "\n",
    "ii. $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2\\ + \\epsilon$\n",
    "\n",
    "iii. $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2\\ + \\beta_3 X^3 + \\epsilon$\n",
    "\n",
    "iv. $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2\\ + \\beta_3 X^3 + \\beta_4 X^4 + \\epsilon$\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree-1 polynomial\n",
      "MSE: 6.260764331604616\n",
      "STD: 14.2550358005433\n",
      "=================================\n",
      "Degree-2 polynomial\n",
      "MSE: 0.9142897072803658\n",
      "STD: 1.3418705329192269\n",
      "=================================\n",
      "Degree-3 polynomial\n",
      "MSE: 0.9268768781648806\n",
      "STD: 1.3495845772769584\n",
      "=================================\n",
      "Degree-4 polynomial\n",
      "MSE: 0.8669116865881086\n",
      "STD: 1.241427626976795\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import LeaveOneOut, KFold, cross_val_score\n",
    "import sklearn.linear_model as sk_lm\n",
    "\n",
    "lm = sk_lm.LinearRegression()\n",
    "#loo = LeaveOneOut()\n",
    "crossvalidation = KFold(n_splits=100, shuffle=True, random_state=1)\n",
    "\n",
    "for i in range(1, 5):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X_current = poly.fit_transform(x.reshape(-1,1))\n",
    "    #model = lm.fit(X_current, y)\n",
    "    scores = cross_val_score(lm, X_current, y,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            cv=crossvalidation,\n",
    "                            n_jobs=1)\n",
    "    print(f'Degree-{i} polynomial\\n'\n",
    "          f'MSE: {np.mean(np.abs(scores))}\\n'\n",
    "          f'STD: {np.std(scores)}\\n'\n",
    "          '=================================')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Repeate (c) using another random seed, and report your results. Are your results the same as what your got in (c)? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree-1 polynomial\n",
      "MSE: 6.260764331604616\n",
      "STD: 14.2550358005433\n",
      "=================================\n",
      "Degree-2 polynomial\n",
      "MSE: 0.9142897072803658\n",
      "STD: 1.3418705329192266\n",
      "=================================\n",
      "Degree-3 polynomial\n",
      "MSE: 0.9268768781648805\n",
      "STD: 1.3495845772769584\n",
      "=================================\n",
      "Degree-4 polynomial\n",
      "MSE: 0.8669116865881086\n",
      "STD: 1.2414276269767952\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=100, shuffle=True, random_state=1000)\n",
    "\n",
    "for i in range(1, 5):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X_current = poly.fit_transform(x.reshape(-1,1))\n",
    "    #model = lm.fit(X_current, y)\n",
    "    scores = cross_val_score(lm, X_current, y,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            cv=crossvalidation)\n",
    "    print(f'Degree-{i} polynomial\\n'\n",
    "          f'MSE: {np.mean(np.abs(scores))}\\n'\n",
    "          f'STD: {np.std(scores)}\\n'\n",
    "          '=================================')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the result is exactly same as that in (c), because we split the data set into 100 folds of a single observation, and the 100 folds are exactly same under different random states.\n",
    "\n",
    "(e) Which of the models in (c) had the smallest LOOCV error? Is this what you expected? Explain your answer.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "The 4th model has the smallest LOOCV error, which is not what I expected. **(I don't know the reason.)**\n",
    "\n",
    "\n",
    "(f) Comment on the statistical significance of the coefficient estimates that results from each of the models in (c) using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   163.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>1.24e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:27:02</td>     <th>  Log-Likelihood:    </th> <td> -130.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   271.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    95</td>      <th>  BIC:               </th> <td>   284.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    0.3140</td> <td>    0.136</td> <td>    2.311</td> <td> 0.023</td> <td>    0.044</td> <td>    0.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X</th>              <td>    0.9127</td> <td>    0.183</td> <td>    4.999</td> <td> 0.000</td> <td>    0.550</td> <td>    1.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.power(X, 2)</th> <td>   -2.5445</td> <td>    0.248</td> <td>  -10.264</td> <td> 0.000</td> <td>   -3.037</td> <td>   -2.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.power(X, 3)</th> <td>    0.0992</td> <td>    0.064</td> <td>    1.556</td> <td> 0.123</td> <td>   -0.027</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.power(X, 4)</th> <td>    0.1394</td> <td>    0.057</td> <td>    2.437</td> <td> 0.017</td> <td>    0.026</td> <td>    0.253</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.537</td> <th>  Durbin-Watson:     </th> <td>   2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.464</td> <th>  Jarque-Bera (JB):  </th> <td>   1.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.238</td> <th>  Prob(JB):          </th> <td>   0.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.184</td> <th>  Cond. No.          </th> <td>    15.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.873\n",
       "Model:                            OLS   Adj. R-squared:                  0.867\n",
       "Method:                 Least Squares   F-statistic:                     163.0\n",
       "Date:                Wed, 13 Jan 2021   Prob (F-statistic):           1.24e-41\n",
       "Time:                        22:27:02   Log-Likelihood:                -130.63\n",
       "No. Observations:                 100   AIC:                             271.3\n",
       "Df Residuals:                      95   BIC:                             284.3\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          0.3140      0.136      2.311      0.023       0.044       0.584\n",
       "X                  0.9127      0.183      4.999      0.000       0.550       1.275\n",
       "np.power(X, 2)    -2.5445      0.248    -10.264      0.000      -3.037      -2.052\n",
       "np.power(X, 3)     0.0992      0.064      1.556      0.123      -0.027       0.226\n",
       "np.power(X, 4)     0.1394      0.057      2.437      0.017       0.026       0.253\n",
       "==============================================================================\n",
       "Omnibus:                        1.537   Durbin-Watson:                   2.100\n",
       "Prob(Omnibus):                  0.464   Jarque-Bera (JB):                1.088\n",
       "Skew:                          -0.238   Prob(JB):                        0.581\n",
       "Kurtosis:                       3.184   Cond. No.                         15.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'X':x, 'Y':y})\n",
    "lg_fit = smf.ols('Y~X+np.power(X,2)+np.power(X,3)+np.power(X,4)', \n",
    "                 data=data).fit()\n",
    "lg_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   304.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>1.47e-42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:27:02</td>     <th>  Log-Likelihood:    </th> <td> -134.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   274.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   282.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    0.1350</td> <td>    0.115</td> <td>    1.169</td> <td> 0.245</td> <td>   -0.094</td> <td>    0.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X</th>              <td>    1.0936</td> <td>    0.107</td> <td>   10.229</td> <td> 0.000</td> <td>    0.881</td> <td>    1.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.power(X, 2)</th> <td>   -1.9846</td> <td>    0.085</td> <td>  -23.331</td> <td> 0.000</td> <td>   -2.153</td> <td>   -1.816</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.893</td> <th>  Durbin-Watson:     </th> <td>   2.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.640</td> <th>  Jarque-Bera (JB):  </th> <td>   0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.170</td> <th>  Prob(JB):          </th> <td>   0.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.132</td> <th>  Cond. No.          </th> <td>    2.10</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.863\n",
       "Model:                            OLS   Adj. R-squared:                  0.860\n",
       "Method:                 Least Squares   F-statistic:                     304.9\n",
       "Date:                Wed, 13 Jan 2021   Prob (F-statistic):           1.47e-42\n",
       "Time:                        22:27:02   Log-Likelihood:                -134.42\n",
       "No. Observations:                 100   AIC:                             274.8\n",
       "Df Residuals:                      97   BIC:                             282.7\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          0.1350      0.115      1.169      0.245      -0.094       0.364\n",
       "X                  1.0936      0.107     10.229      0.000       0.881       1.306\n",
       "np.power(X, 2)    -1.9846      0.085    -23.331      0.000      -2.153      -1.816\n",
       "==============================================================================\n",
       "Omnibus:                        0.893   Durbin-Watson:                   2.152\n",
       "Prob(Omnibus):                  0.640   Jarque-Bera (JB):                0.552\n",
       "Skew:                          -0.170   Prob(JB):                        0.759\n",
       "Kurtosis:                       3.132   Cond. No.                         2.10\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_fit = smf.ols('Y~X+np.power(X,2)', \n",
    "                 data=data).fit()\n",
    "lg_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   204.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Jan 2021</td> <th>  Prob (F-statistic):</th> <td>1.40e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:27:02</td>     <th>  Log-Likelihood:    </th> <td> -133.66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   275.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    96</td>      <th>  BIC:               </th> <td>   285.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    0.1280</td> <td>    0.115</td> <td>    1.111</td> <td> 0.269</td> <td>   -0.101</td> <td>    0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X</th>              <td>    0.9065</td> <td>    0.187</td> <td>    4.842</td> <td> 0.000</td> <td>    0.535</td> <td>    1.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.power(X, 2)</th> <td>   -1.9753</td> <td>    0.085</td> <td>  -23.187</td> <td> 0.000</td> <td>   -2.144</td> <td>   -1.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.power(X, 3)</th> <td>    0.0788</td> <td>    0.065</td> <td>    1.216</td> <td> 0.227</td> <td>   -0.050</td> <td>    0.208</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.539</td> <th>  Durbin-Watson:     </th> <td>   2.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.463</td> <th>  Jarque-Bera (JB):  </th> <td>   1.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.236</td> <th>  Prob(JB):          </th> <td>   0.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.193</td> <th>  Cond. No.          </th> <td>    5.53</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.865\n",
       "Model:                            OLS   Adj. R-squared:                  0.861\n",
       "Method:                 Least Squares   F-statistic:                     204.8\n",
       "Date:                Wed, 13 Jan 2021   Prob (F-statistic):           1.40e-41\n",
       "Time:                        22:27:02   Log-Likelihood:                -133.66\n",
       "No. Observations:                 100   AIC:                             275.3\n",
       "Df Residuals:                      96   BIC:                             285.7\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          0.1280      0.115      1.111      0.269      -0.101       0.357\n",
       "X                  0.9065      0.187      4.842      0.000       0.535       1.278\n",
       "np.power(X, 2)    -1.9753      0.085    -23.187      0.000      -2.144      -1.806\n",
       "np.power(X, 3)     0.0788      0.065      1.216      0.227      -0.050       0.208\n",
       "==============================================================================\n",
       "Omnibus:                        1.539   Durbin-Watson:                   2.129\n",
       "Prob(Omnibus):                  0.463   Jarque-Bera (JB):                1.081\n",
       "Skew:                          -0.236   Prob(JB):                        0.583\n",
       "Kurtosis:                       3.193   Cond. No.                         5.53\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'X':x, 'Y':y})\n",
    "lg_fit = smf.ols('Y~X+np.power(X,2)+np.power(X,3)', \n",
    "                 data=data).fit()\n",
    "lg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the *p*-values associated with the coefficient $\\beta_3$ and $\\beta_4$ are not statistically significant, while those associated with the $\\beta_1$ and $\\beta_2$ are statistically significant. This does not agree with our cross-validation resluts which have a minimum value for the 4th model.\n",
    "\n",
    "**Q9**. We will now consider the **Boston** housing data set.\n",
    "\n",
    "(a) Based on this data set, provide an estimate for the population mean of **medv**. Call this estimate $\\hat{\\mu}$.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv('../data/Boston.csv',\n",
    "                    na_values='?')\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110677"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_medv = boston['medv'].mean()\n",
    "mu_medv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Provide an estimate of the standard error of $\\hat{\\mu}$. Interpret this result.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40886114749753505"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ste_medv = boston['medv'].std() / np.sqrt(len(boston))\n",
    "ste_medv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Now estimate the standard error of $\\hat{\\mu}$ using the bootstrap. How does this compare to your answer from (b)?\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Statistics:\n",
      "Estimate: 22.527240316205493\n",
      "STD: 0.415725100380502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_mean(df):\n",
    "    return df['medv'].mean()\n",
    "\n",
    "boot(boston, get_mean, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error of $\\hat{\\mu}$ using the bootstrap is 0.4157, very close to that obtained in (b).\n",
    "\n",
    "(d) Based on your bootstrap estimate from (c), provide a 95% confidence interval for the mean of **medv**. Compare it to the results obtained using `zconfint()` function from `statsmodels`.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.69578, 23.3587]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = [22.52724-2*0.41573, 22.52724+2*0.41573]\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.73145320033779, 23.334159447883565)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.weightstats import zconfint\n",
    "zconfint(boston['medv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the bootstrap confidence interval is very close to the one provided by the `zconfint()` function.\n",
    "\n",
    "(e) Based on this data set, provide an estimate, $\\hat{\\mu}_{med}$, for the median value of **medv** in the population.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Statistics:\n",
      "Estimate: 21.189000000000096\n",
      "STD: 0.38552431829911815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_median(df):\n",
    "    return df['medv'].median()\n",
    "\n",
    "boot(boston, get_median, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['medv'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the bootstrap median value is very close to the one provided by the `median()` function.\n",
    "\n",
    "(f) Estimate the standard eror of the median using the bootstrap. Comment on your findings.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "According to (e), we get an estimated standard error of 0.3855 for the median value.\n",
    "\n",
    "(g) Based on this data set, provide an estimate for the tenth percentile of **medv** in Boston suburbs. Call this quantity $\\hat{\\mu}_{0.1}$.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.75"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['medv'].quantile(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) Use the bootstrap to estimate the standard error of $\\hat{\\mu}_{0.1}$. Comment on your findings.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Statistics:\n",
      "Estimate: 12.779900000000001\n",
      "STD: 0.4945108593347572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_quantile(df):\n",
    "    return df['medv'].quantile(0.1)\n",
    "\n",
    "boot(boston, get_quantile, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an estimated tenth percentile value of 12.78 that is very close to the value obtained in (g), with a standard error of 0.4945 that is relatively small compared to the percentile value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
