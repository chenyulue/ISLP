{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptual\n",
    "\n",
    "1. Prove that $\\alpha$ given by (5.6) does indeed minimize $Var(\\alpha X + (1 - \\alpha) Y$.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "Three properties that is useful for the deduction:\n",
    "* $Cov(a \\cdot X, b\\cdot Y) = ab \\cdot Cov(X, Y)$\n",
    "* $Var(X \\pm Y) = Var(X) + Var(Y) \\pm 2Cov(X, Y)$\n",
    "* $Var(a \\cdot X) = a^2 Var(X)$\n",
    "\n",
    "$$\\begin{align}Var(\\alpha X + (1-\\alpha)Y) &= Var(\\alpha X) + Var((1-\\alpha)Y) + 2Cov(\\alpha X, (1-\\alpha)Y) \\\\ &= \\alpha^2 Var(X) + (1-\\alpha)^2 Var(Y) + 2 \\alpha (1-\\alpha) Cov(X, Y) \\end{align}$$\n",
    "\n",
    "When $Var(\\alpha X + (1-\\alpha)Y)$ gets a minimum value, its derivative should be zero such that:\n",
    "\n",
    "$$\\begin{align} 2\\alpha Var(X) - 2（1 - \\alpha)Var(Y) + (2 - 4\\alpha)Cov(X, Y) &= 0 \\\\ \\Longrightarrow \\alpha Var(X) + \\alpha Var(Y) - Var(Y) + Cov(X, Y) - 2 \\alpha Cov(X, Y) &= 0 \\\\ \\Longrightarrow \\alpha = \\frac{Var(Y) - Cov(X, Y)}{Var(X) + Var(Y) - 2Cov(X, Y)} \\\\ \\Longrightarrow \\alpha = \\frac{\\sigma_Y^2 - \\sigma_{XY}}{\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}}\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We will now derive the probability that a given observation is part of a bootstrap sample. Suppose that we obtain a bootstrap sample from a set of *n* observations.\n",
    "\n",
    "(a) What is the probability that the first bootstrap observation is *not* the *j*th observation from the original sample?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "Let us denote this probability by $P_j$. As the probability of selecting a particular $x_j$ from the set $x_1,...,x_n$ is $1/n$, then the desired probability is\n",
    "\n",
    "$$P_j = 1 - \\frac1n$$\n",
    "\n",
    "(b) What is the probability that the second bootstrap observation is *not* the *j*th observation from the original sample?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "The probability is $1 - \\frac1n$ with the same reason as above.\n",
    "\n",
    "(c) Argue that the probability that the *j*th observation is *not* in the bootstrap sample is $(1 - 1/n)^n$.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "As bootstrapping the sample with replacement, we have that the probability that the *j*th observation is not in the bootstrap sample is the product of the probabilities that each bootstrap observation is not the *j*th observation from the original sample\n",
    "\n",
    "$$(1-1/n)\\cdot \\cdot \\cdot(1-1/n) = (1-1/n)^n$$\n",
    "\n",
    "as these probabilities are independant.\n",
    "\n",
    "(d) When $n=5$, what is the probability that the *j*th observation is in the bootstrap sample?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "According to the description in (c), the probability that *j*th observation is in the bootstrap sample is $1 - (1 - 1/5)^5 = 0.672$.\n",
    "\n",
    "(e) When $n=100$, what is the probability that the *j*th observation is in the bootstrap sample?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "The probability is $1 - (1 - 1/100)^{100} = 0.634$.\n",
    "\n",
    "(f) When $n=10,000$, what is the probability that the *j*th  observation is in the bootstrap sample?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "The probability is $1 - (1 - 1/10000)^{10000} = 0.632$.\n",
    "\n",
    "(g) Create a plot that displays, for each integer value of $n$ from 1 to 100,000, the probability that the *j*th observation is in the bootstrap sample.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n = np.arange(1,100001)\n",
    "p = 1 - (1 - 1/n)**n\n",
    "plt.scatter(n, p)\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, we can see that the probability drops quickly and reaches an asymptote at about $0.632$.\n",
    "\n",
    "(h) We will now investigate numerically the probability that a bootstrap sample of size $n=100$ contains the *j*th observation. Here $j=4$. We repeatedly create bootstrap samples, and each time we record whether or not the fourth observation is contained in the bootstrap sample. Comment on the results obtained.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s = pd.Series(range(1,101))\n",
    "store = [sum(s.sample(frac=1, replace=True)==4)>0\n",
    "         for _ in range(1,10001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6401"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the exponential function satisfies:\n",
    "\n",
    "$$e^x = \\lim\\limits_{n \\to \\infty} (1 + \\frac{x}{n})^n$$\n",
    "\n",
    "Hence, we can easily see that the probability $P_j$ that the *j*th observation is not in the bootstrap sample is:\n",
    "\n",
    "$$\\begin{align} P_j &= \\lim\\limits_{n \\to \\infty} (1 - \\frac1n)^n \\\\ &= e^{-1} \\end{align}$$\n",
    "\n",
    "Therefore, as $n$ increases, the probability of the *j*th observation being in the bootstrap samples is:\n",
    "\n",
    "$$1 - P_j = 1 - e^{-1} \\approx 0.63212$$.\n",
    "\n",
    "The above demonstrates the often encountered statement about the bootstrap:\n",
    "\n",
    "> On average, each bootstrap sample makes use of around two-thirds of the observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We now review *k*-fold cross-validation\n",
    "\n",
    "(a) Explain how *k*-fold cross-validatino is implemented.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "The *k*-fold cross validation is implemented by taking the $n$ observations and randomly splitting it into $k$ non-overlapping groups with the length of (approximately) $n/k$. These groups acts as a validation set, and the remainder (of length n−n/k) acts as a training set. The test error is then estimated by averaging the $k$ resulting *MSE* estimates.\n",
    "\n",
    "(b) What are the advantages and disadvantages of *k*-fold cross-validation relative to:\n",
    "* The validation set approach?\n",
    "* LOOCV?\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "i. The validation set approach:\n",
    "\n",
    "The validation set approach has two main drawbacks compared to *k*-fold cross-validation. \n",
    "* First, the validation estimate of the test error rate can be highly variable (depending on precisely which observations are included in the training set and which observations are included in the validation set). \n",
    "* Second, only a subset of the observations are used to fit the model. Since statistical methods tend to perform worse when trained on fewer observations, this suggests that the validation set error rate may tend to overestimate the test error rate for the model fit on the entire data set.\n",
    "\n",
    "ii. LOOCV:\n",
    "\n",
    "The LOOCV cross-validation approach is a special case of k-fold cross-validation in which $k=n$. This approach has two drawbacks compared to k-fold cross-validation. \n",
    "* First, it requires fitting the potentially computationally expensive model $n$ times compared to *k*-fold cross-validation which requires the model to be fitted only $k$ times. \n",
    "* Second, the LOOCV cross-validation approach may give approximately unbiased estimates of the test error, since each training set contains $n−1$ observations; however, this approach has higher variance than *k*-fold cross-validation (since we are averaging the outputs of $n$ fitted models trained on an almost identical set of observations, these outputs are highly correlated, and the mean of highly correlated quantities has higher variance than less correlated ones). \n",
    "\n",
    "So, there is a bias-variance trade-off associated with the choice of $k$ in *k*-fold cross-validation; typically using $k=5$ or $k=10$ yield test error rate estimates that suffer neither from excessively high bias nor from very high variance.\n",
    "\n",
    "4. Suppose that we use some statistical learning method to make a prediction for the response *Y* for a particular value of the predictor *X*. Carefully describe how we might estimate the standard deviation of our prediction.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "We may estimate the standard deviation of our prediction by using the bootstrap method. In this case, rather than obtaining new independant data sets from the population and fitting our model on those data sets, we instead obtain repeated random samples from the original data set. In this case, we perform sampling with replacement $B$ times and then find the corresponding estimates and the standard deviation of those $B$ estimates by using equation (5.8).\n",
    "\n",
    "# Applied\n",
    "\n",
    "5. In Chapter 4, we used logitic regression to predict the probability of **default** using **income** and **balance** on the **Default** data set. We will now estimate the test error of this logistic regression model using the validation set approach.\n",
    "\n",
    "(a) Fit a logistic regression model that uses **income** and **balance** to predict **default**.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "1      No      No   729.526495  44361.625074\n",
       "2      No     Yes   817.180407  12106.134700\n",
       "3      No      No  1073.549164  31767.138947\n",
       "4      No      No   529.250605  35704.493935\n",
       "5      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default = pd.read_csv('../data/Default.csv',\n",
    "                     na_values='?',\n",
    "                     index_col=0)\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>['default[No]', 'default[Yes]']</td> <th>  No. Observations:  </th>  <td> 10000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                         <td>GLM</td>               <th>  Df Residuals:      </th>  <td>  9997</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>               <td>Binomial</td>             <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>                <td>logit</td>              <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                       <td>IRLS</td>               <th>  Log-Likelihood:    </th> <td> -789.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                   <td>Sun, 10 Jan 2021</td>         <th>  Deviance:          </th> <td>  1579.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                       <td>22:29:37</td>             <th>  Pearson chi2:      </th> <td>6.95e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>                 <td>9</td>                <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>            <td>nonrobust</td>            <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   11.5405</td> <td>    0.435</td> <td>   26.544</td> <td> 0.000</td> <td>   10.688</td> <td>   12.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td>-2.081e-05</td> <td> 4.99e-06</td> <td>   -4.174</td> <td> 0.000</td> <td>-3.06e-05</td> <td> -1.1e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>   -0.0056</td> <td>    0.000</td> <td>  -24.835</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                        Generalized Linear Model Regression Results                        \n",
       "===========================================================================================\n",
       "Dep. Variable:     ['default[No]', 'default[Yes]']   No. Observations:                10000\n",
       "Model:                                         GLM   Df Residuals:                     9997\n",
       "Model Family:                             Binomial   Df Model:                            2\n",
       "Link Function:                               logit   Scale:                          1.0000\n",
       "Method:                                       IRLS   Log-Likelihood:                -789.48\n",
       "Date:                             Sun, 10 Jan 2021   Deviance:                       1579.0\n",
       "Time:                                     22:29:37   Pearson chi2:                 6.95e+03\n",
       "No. Iterations:                                  9                                         \n",
       "Covariance Type:                         nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     11.5405      0.435     26.544      0.000      10.688      12.393\n",
       "income     -2.081e-05   4.99e-06     -4.174      0.000   -3.06e-05    -1.1e-05\n",
       "balance       -0.0056      0.000    -24.835      0.000      -0.006      -0.005\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_fit = smf.glm('default~income+balance',\n",
    "                 data=default,\n",
    "                 family=sm.families.Binomial()).fit()\n",
    "lg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Using the validation set approach, estimate the test error of this model.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0308"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_test_error(df): \n",
    "    # Split the sample set into a training set and a validation set\n",
    "    df_train = df.sample(frac=0.5)\n",
    "    df_test = df[~df.isin(df_train)].dropna(how='all')\n",
    "    # Fit a multiple logistic regression model using only the training observations\n",
    "    lg_fit = smf.glm('default~income+balance',\n",
    "                     data=df,\n",
    "                     family=sm.families.Binomial(),\n",
    "                     subset=df_train.index).fit()\n",
    "    # Obtain a prediction of default status for each individual in the validation set.\n",
    "    lg_prob = lg_fit.predict(df_test)\n",
    "    lg_pred = np.where(lg_prob>0.5, 'No', 'Yes')\n",
    "    # Compute the validation set error\n",
    "    return (lg_pred != df_test['default']).mean()\n",
    "\n",
    "get_test_error(default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a $2.74\\%$ test error with the validation set approach.\n",
    "\n",
    "(c) Repeate the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0: 0.0274\n",
      "No.1: 0.026\n",
      "No.2: 0.0276\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f'No.{i}: {get_test_error(default)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the validation estimate of the test error rate can be variable, depending on precisely which observations are included in the training set and which observations are included in the validation set.\n",
    "\n",
    "(d). Now consider a logistic regression model that predicts the probability of **default** using **income**, **balance**, and a dummy variable for **student**. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for **student** leads to a reduction in the test error rate.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0272"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_train = default.sample(frac=0.5)\n",
    "default_test = default[~default.isin(default_train)].dropna(how='all')\n",
    "\n",
    "lg_fit = smf.glm('default~income+balance+C(student)',\n",
    "                 data=default,\n",
    "                 family=sm.families.Binomial(),\n",
    "                 subset=default_train.index).fit()\n",
    "lg_prob = lg_fit.predict(default_test)\n",
    "lg_pred = np.where(lg_prob>0.5, 'No', 'Yes')\n",
    "\n",
    "(lg_pred != default_test['default']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem that adding the \"student\" dummy variable leads to a reduction in the validation set estimate of the test error rate.\n",
    "\n",
    "6. We continue to consider the use of a logistic regression model to predict the probability of **default** using **income** and **balance** on the **Default** data set. In particular, we will now compute estimates for the standard errors of the **income** and **balance** logistic regression coefficients in two different ways: (1) using the bootstrap, and (2) using the standard formular for computing the standard errors in the `glm()` function.\n",
    "\n",
    "(a) Using the `summary()` method and `glm()` funtion, determine the estimated standard errors for the coefficients associated with **income** and **balance** in a multiple logistic regression model that uses both predictors.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>['default[No]', 'default[Yes]']</td> <th>  No. Observations:  </th>  <td> 10000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                         <td>GLM</td>               <th>  Df Residuals:      </th>  <td>  9997</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>               <td>Binomial</td>             <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>                <td>logit</td>              <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                       <td>IRLS</td>               <th>  Log-Likelihood:    </th> <td> -789.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                   <td>Sun, 10 Jan 2021</td>         <th>  Deviance:          </th> <td>  1579.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                       <td>22:29:38</td>             <th>  Pearson chi2:      </th> <td>6.95e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>                 <td>9</td>                <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>            <td>nonrobust</td>            <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   11.5405</td> <td>    0.435</td> <td>   26.544</td> <td> 0.000</td> <td>   10.688</td> <td>   12.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td>-2.081e-05</td> <td> 4.99e-06</td> <td>   -4.174</td> <td> 0.000</td> <td>-3.06e-05</td> <td> -1.1e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>   -0.0056</td> <td>    0.000</td> <td>  -24.835</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                        Generalized Linear Model Regression Results                        \n",
       "===========================================================================================\n",
       "Dep. Variable:     ['default[No]', 'default[Yes]']   No. Observations:                10000\n",
       "Model:                                         GLM   Df Residuals:                     9997\n",
       "Model Family:                             Binomial   Df Model:                            2\n",
       "Link Function:                               logit   Scale:                          1.0000\n",
       "Method:                                       IRLS   Log-Likelihood:                -789.48\n",
       "Date:                             Sun, 10 Jan 2021   Deviance:                       1579.0\n",
       "Time:                                     22:29:38   Pearson chi2:                 6.95e+03\n",
       "No. Iterations:                                  9                                         \n",
       "Covariance Type:                         nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     11.5405      0.435     26.544      0.000      10.688      12.393\n",
       "income     -2.081e-05   4.99e-06     -4.174      0.000   -3.06e-05    -1.1e-05\n",
       "balance       -0.0056      0.000    -24.835      0.000      -0.006      -0.005\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_fit = smf.glm('default~income+balance',\n",
    "                 data=default,\n",
    "                 family=sm.families.Binomial()).fit()\n",
    "lg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `glm()` estimates of the standard errors for the coefficients $\\beta_0$, $\\beta_1$ and $\\beta_2$ are 0.435, 4.99^-6, and almose zero, respectively.\n",
    "\n",
    "(b) Write a function, `coef()`, that takes as input the **Default** data set, and that outputs the coefficients estimates for **income** and **balance** in the multiple logistic regression model.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef(df):\n",
    "    lg_fit = smf.glm('default~income+balance',\n",
    "                      data=df,\n",
    "                      family=sm.families.Binomial()).fit()\n",
    "    return lg_fit.params.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Use the `boot()` function together with the `coef()` function to estimate the standard errors of the logistic regression coefficients for **income** and **balance**.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot(df, fun, n):\n",
    "    tresult = []\n",
    "    for i in range(0, n):\n",
    "        dfsample = df.sample(frac=1, replace=True)\n",
    "        result = fun(df)\n",
    "        tresult.append(result)\n",
    "    estimate = sum(tresult)/n\n",
    "    std_est = np.std(tresult, axis=0)\n",
    "    print('Bootstrap Statistics:\\n'\n",
    "         f'Estimate: {estimate}\\n'\n",
    "         f'STD: {std_est}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Statistics:\n",
      "Estimate: [ 1.15404684e+01 -2.08089755e-05 -5.64710295e-03]\n",
      "STD: [1.66977543e-13 2.06676039e-19 3.81639165e-17]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boot(default, coef, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. In this exercises, we use the `glm()` and `predict()` functions, and a `for` loop to compute the LOOCV test error estimate for a simple logistic regression model on the **Weekly** data set. \n",
    "\n",
    "(a) Fig a logistic regression model that predicts **Direction** using **Lag1** and **Lag2**.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
       "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
       "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
       "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up\n",
       "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up\n",
       "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly = pd.read_csv('../data/Weekly.csv',\n",
    "                     na_values='?')\n",
    "weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>['Direction[Down]', 'Direction[Up]']</td> <th>  No. Observations:  </th>  <td>  1089</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                            <td>GLM</td>                 <th>  Df Residuals:      </th>  <td>  1086</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>                  <td>Binomial</td>               <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>                   <td>logit</td>                <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                          <td>IRLS</td>                 <th>  Log-Likelihood:    </th> <td> -744.11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                      <td>Sun, 10 Jan 2021</td>           <th>  Deviance:          </th> <td>  1488.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                          <td>22:29:38</td>               <th>  Pearson chi2:      </th> <td>1.09e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>                    <td>4</td>                  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>               <td>nonrobust</td>              <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.2212</td> <td>    0.061</td> <td>   -3.599</td> <td> 0.000</td> <td>   -0.342</td> <td>   -0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>      <td>    0.0387</td> <td>    0.026</td> <td>    1.477</td> <td> 0.140</td> <td>   -0.013</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>      <td>   -0.0602</td> <td>    0.027</td> <td>   -2.270</td> <td> 0.023</td> <td>   -0.112</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Generalized Linear Model Regression Results                           \n",
       "================================================================================================\n",
       "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1089\n",
       "Model:                                              GLM   Df Residuals:                     1086\n",
       "Model Family:                                  Binomial   Df Model:                            2\n",
       "Link Function:                                    logit   Scale:                          1.0000\n",
       "Method:                                            IRLS   Log-Likelihood:                -744.11\n",
       "Date:                                  Sun, 10 Jan 2021   Deviance:                       1488.2\n",
       "Time:                                          22:29:38   Pearson chi2:                 1.09e+03\n",
       "No. Iterations:                                       4                                         \n",
       "Covariance Type:                              nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.2212      0.061     -3.599      0.000      -0.342      -0.101\n",
       "Lag1           0.0387      0.026      1.477      0.140      -0.013       0.090\n",
       "Lag2          -0.0602      0.027     -2.270      0.023      -0.112      -0.008\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_fit = smf.glm('Direction~Lag1+Lag2',\n",
    "                 data=weekly,\n",
    "                 family=sm.families.Binomial()).fit()\n",
    "lg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Fit a logistic regression model that predicts **Direction** using **Lag1** and **Lag2** *using all but the first observation*.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>['Direction[Down]', 'Direction[Up]']</td> <th>  No. Observations:  </th>  <td>  1088</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                            <td>GLM</td>                 <th>  Df Residuals:      </th>  <td>  1085</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>                  <td>Binomial</td>               <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>                   <td>logit</td>                <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                          <td>IRLS</td>                 <th>  Log-Likelihood:    </th> <td> -743.26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                      <td>Sun, 10 Jan 2021</td>           <th>  Deviance:          </th> <td>  1486.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                          <td>22:29:38</td>               <th>  Pearson chi2:      </th> <td>1.09e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>                    <td>4</td>                  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>               <td>nonrobust</td>              <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.2232</td> <td>    0.061</td> <td>   -3.630</td> <td> 0.000</td> <td>   -0.344</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag1</th>      <td>    0.0384</td> <td>    0.026</td> <td>    1.466</td> <td> 0.143</td> <td>   -0.013</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lag2</th>      <td>   -0.0608</td> <td>    0.027</td> <td>   -2.291</td> <td> 0.022</td> <td>   -0.113</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Generalized Linear Model Regression Results                           \n",
       "================================================================================================\n",
       "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1088\n",
       "Model:                                              GLM   Df Residuals:                     1085\n",
       "Model Family:                                  Binomial   Df Model:                            2\n",
       "Link Function:                                    logit   Scale:                          1.0000\n",
       "Method:                                            IRLS   Log-Likelihood:                -743.26\n",
       "Date:                                  Sun, 10 Jan 2021   Deviance:                       1486.5\n",
       "Time:                                          22:29:38   Pearson chi2:                 1.09e+03\n",
       "No. Iterations:                                       4                                         \n",
       "Covariance Type:                              nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.2232      0.061     -3.630      0.000      -0.344      -0.103\n",
       "Lag1           0.0384      0.026      1.466      0.143      -0.013       0.090\n",
       "Lag2          -0.0608      0.027     -2.291      0.022      -0.113      -0.009\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = weekly.index.difference([0])\n",
    "lg_fit = smf.glm('Direction~Lag1+Lag2',\n",
    "                 data=weekly,\n",
    "                 family=sm.families.Binomial(),\n",
    "                 subset=train).fit()\n",
    "lg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Use the model from (b) to predict the direction of the first observation. Was this observation correctly classified?\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the first observation is Up ,\n",
      "while the true value is Down\n"
     ]
    }
   ],
   "source": [
    "y_prob = lg_fit.predict(weekly.iloc[[0]])\n",
    "print('Prediction for the first observation is',\n",
    "      'Down' if y_prob[0] > 0.5 else 'Up',\n",
    "      ',\\nwhile the true value is',\n",
    "      weekly['Direction'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this observation is not correctly classified.\n",
    "\n",
    "(d) Write a for loop form $i=1$ to $i=n$, where $n$ is the number of observations in the data set, that performs each of the following steps:\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_num = 0\n",
    "for i in range(len(weekly)):\n",
    "    # Fit a logistic regression model using all but the \n",
    "    # ith observation for predictions\n",
    "    train = weekly.index.difference([i])\n",
    "    lg_fit = smf.glm('Direction~Lag1+Lag2',\n",
    "                     data=weekly,\n",
    "                     family=sm.families.Binomial(),\n",
    "                     subset=train).fit()\n",
    "    # Compute the posterior probability of the market\n",
    "    # moving down for the ith observation\n",
    "    y_prob = lg_fit.predict(weekly.iloc[[0]])[0]\n",
    "    # Use the posterior probability to make a prediction\n",
    "    y_pred = 'Down' if y_prob >= 0.5 else 'Up'\n",
    "    # Determine whether or not an error was made in predicting\n",
    "    # the direction for the ith observation\n",
    "    if y_pred != weekly['Direction'][i]:\n",
    "        error_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Take the average of the $n$ numbers obtained in (d) in order to obtain the LOOCV estimate for the test error. Comment on the results.\n",
    "\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_num / len(weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LOOCV estimate for the test error is 44.44%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
