{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hollow-payroll",
   "metadata": {},
   "source": [
    "# 6.5 Lab 1: Subset Selection Methods\n",
    "## 6.5.1 Best Subset Selection\n",
    "We first apply the best subset selection approach to the **Hitters** data, and wish to predict a baseball player's **Salary** on the basis of various statistics associated with performance in the previous year.\n",
    "\n",
    "First of all, we load the related data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statutory-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excited-token",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Student</th>\n",
       "      <th>Married</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.891</td>\n",
       "      <td>3606</td>\n",
       "      <td>283</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106.025</td>\n",
       "      <td>6645</td>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Asian</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.593</td>\n",
       "      <td>7075</td>\n",
       "      <td>514</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148.924</td>\n",
       "      <td>9504</td>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.882</td>\n",
       "      <td>4897</td>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Income  Limit  Rating  Cards  Age  Education  Gender Student Married  \\\n",
       "1   14.891   3606     283      2   34         11    Male      No     Yes   \n",
       "2  106.025   6645     483      3   82         15  Female     Yes     Yes   \n",
       "3  104.593   7075     514      4   71         11    Male      No      No   \n",
       "4  148.924   9504     681      3   36         11  Female      No      No   \n",
       "5   55.882   4897     357      2   68         16    Male      No     Yes   \n",
       "\n",
       "   Ethnicity  Balance  \n",
       "1  Caucasian      333  \n",
       "2      Asian      903  \n",
       "3      Asian      580  \n",
       "4      Asian      964  \n",
       "5  Caucasian      331  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters = pd.read_csv('../data/Credit.csv', \n",
    "                     na_values='?',\n",
    "                     index_col=0).dropna();\n",
    "hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "distinguished-basin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-stephen",
   "metadata": {},
   "source": [
    "Some of the predictors are categorical, so we'd like to generate dummy variables for them, separate out the response variable and predictors. We use the `patsy` package to generate the corresponding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lightweight-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sum = '+'.join(hitters.columns.difference(['Balance']))\n",
    "formula = f'Balance~{pred_sum}-1'\n",
    "y, X = patsy.dmatrices(formula, hitters, return_type='matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-raise",
   "metadata": {},
   "source": [
    "Next we can define a `best_subset` function to select the best subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baking-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestSubset:\n",
    "\n",
    "    def __init__(self, model, X, y, assess):\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.assess = assess\n",
    "        self.num_features = np.shape(self.X)[1]\n",
    "\n",
    "    def get_subset(self, subsets):\n",
    "        def compute_training_rss():\n",
    "            for idx in subsets:\n",
    "                model_fit = self.model.fit(self.X[:, idx], self.y)\n",
    "                rss = ((model_fit.predict(self.X[:, idx]) - self.y) ** 2).sum()\n",
    "                yield (idx, rss)\n",
    "        return min(compute_training_rss(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    def best_subset_cv(self, cv=5, features=None):\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        from itertools import combinations\n",
    "        if features is None:\n",
    "            num = self.num_features\n",
    "        else:\n",
    "            num = features\n",
    "        def compute_test_score():\n",
    "            for k in range(num):\n",
    "                subset = self.get_subset(combinations(range(self.num_features), k+1))\n",
    "                score = -1*cross_val_score(self.model, \n",
    "                                        self.X[:, subset], self.y,\n",
    "                                        scoring='neg_mean_squared_error',\n",
    "                                        cv=cv).mean()\n",
    "                yield (subset, score)\n",
    "        return min(compute_test_score(), key=lambda x:x[1])[0]\n",
    "\n",
    "\n",
    "    def best_subset(self, cv, features):\n",
    "        return self.best_subset_cv(cv=cv, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "thick-green",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "best_subset() missing 2 required positional arguments: 'cv' and 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-5e3b09b2024e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mselect_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBestSubset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mselect_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_subset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: best_subset() missing 2 required positional arguments: 'cv' and 'features'"
     ]
    }
   ],
   "source": [
    "select_model = BestSubset(reg, X, y, 'cv')\n",
    "select_model.best_subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interested-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "european-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg_fit = reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "constant-combination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (400, 12)\n",
       "  Columns:\n",
       "    ['Ethnicity[African American]',\n",
       "     'Ethnicity[Asian]',\n",
       "     'Ethnicity[Caucasian]',\n",
       "     'Gender[T.Male]',\n",
       "     'Married[T.Yes]',\n",
       "     'Student[T.Yes]',\n",
       "     'Age',\n",
       "     'Cards',\n",
       "     'Education',\n",
       "     'Income',\n",
       "     'Limit',\n",
       "     'Rating']\n",
       "  Terms:\n",
       "    'Ethnicity' (columns 0:3)\n",
       "    'Gender' (column 3)\n",
       "    'Married' (column 4)\n",
       "    'Student' (column 5)\n",
       "    'Age' (column 6)\n",
       "    'Cards' (column 7)\n",
       "    'Education' (column 8)\n",
       "    'Income' (column 9)\n",
       "    'Limit' (column 10)\n",
       "    'Rating' (column 11)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "detailed-lounge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Ordinary least squares Linear Regression.\n",
       "\n",
       "LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
       "to minimize the residual sum of squares between the observed targets in\n",
       "the dataset, and the targets predicted by the linear approximation.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "fit_intercept : bool, default=True\n",
       "    Whether to calculate the intercept for this model. If set\n",
       "    to False, no intercept will be used in calculations\n",
       "    (i.e. data is expected to be centered).\n",
       "\n",
       "normalize : bool, default=False\n",
       "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
       "    If True, the regressors X will be normalized before regression by\n",
       "    subtracting the mean and dividing by the l2-norm.\n",
       "    If you wish to standardize, please use\n",
       "    :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
       "    on an estimator with ``normalize=False``.\n",
       "\n",
       "copy_X : bool, default=True\n",
       "    If True, X will be copied; else, it may be overwritten.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    The number of jobs to use for the computation. This will only provide\n",
       "    speedup for n_targets > 1 and sufficient large problems.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "\n",
       "positive : bool, default=False\n",
       "    When set to ``True``, forces the coefficients to be positive. This\n",
       "    option is only supported for dense arrays.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
       "    Estimated coefficients for the linear regression problem.\n",
       "    If multiple targets are passed during the fit (y 2D), this\n",
       "    is a 2D array of shape (n_targets, n_features), while if only\n",
       "    one target is passed, this is a 1D array of length n_features.\n",
       "\n",
       "rank_ : int\n",
       "    Rank of matrix `X`. Only available when `X` is dense.\n",
       "\n",
       "singular_ : array of shape (min(X, y),)\n",
       "    Singular values of `X`. Only available when `X` is dense.\n",
       "\n",
       "intercept_ : float or array of shape (n_targets,)\n",
       "    Independent term in the linear model. Set to 0.0 if\n",
       "    `fit_intercept = False`.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Ridge : Ridge regression addresses some of the\n",
       "    problems of Ordinary Least Squares by imposing a penalty on the\n",
       "    size of the coefficients with l2 regularization.\n",
       "Lasso : The Lasso is a linear model that estimates\n",
       "    sparse coefficients with l1 regularization.\n",
       "ElasticNet : Elastic-Net is a linear regression\n",
       "    model trained with both l1 and l2 -norm regularization of the\n",
       "    coefficients.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "From the implementation point of view, this is just plain Ordinary\n",
       "Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
       "(scipy.optimize.nnls) wrapped as a predictor object.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.linear_model import LinearRegression\n",
       ">>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
       ">>> # y = 1 * x_0 + 2 * x_1 + 3\n",
       ">>> y = np.dot(X, np.array([1, 2])) + 3\n",
       ">>> reg = LinearRegression().fit(X, y)\n",
       ">>> reg.score(X, y)\n",
       "1.0\n",
       ">>> reg.coef_\n",
       "array([1., 2.])\n",
       ">>> reg.intercept_\n",
       "3.0000...\n",
       ">>> reg.predict(np.array([[3, 5]]))\n",
       "array([16.])\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\xj\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?linear_model.LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "voluntary-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = np.array([[0,0,5],[1,1,3],[2,2,8]]), np.array([10,12,83])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wireless-handle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_fit.rank_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "disabled-stroke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "western-intelligence",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-ca1484b0a053>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "A[[0,2],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-former",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
